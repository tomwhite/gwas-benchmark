{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "champion-religion",
   "metadata": {},
   "source": [
    "Efficient implementation of Dask's `matmul` from https://github.com/dask/dask/pull/7000.\n",
    "This is included here so we don't have to rebuild Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "powered-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dask.array.core import (\n",
    "    asanyarray,\n",
    "    blockwise,\n",
    "    is_scalar_for_elemwise,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "arabic-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_type(*args):\n",
    "    args = [a if is_scalar_for_elemwise(a) else a.dtype for a in args]\n",
    "    return np.result_type(*args)\n",
    "\n",
    "def _matmul(a, b):\n",
    "    chunk = np.matmul(a, b)\n",
    "    # Since we have performed the contraction via matmul\n",
    "    # but blockwise expects all dimensions back, we need\n",
    "    # to add one dummy dimension back\n",
    "    return chunk[..., np.newaxis]\n",
    "\n",
    "\n",
    "def matmul(a, b):\n",
    "    a = asanyarray(a)\n",
    "    b = asanyarray(b)\n",
    "\n",
    "    if a.ndim == 0 or b.ndim == 0:\n",
    "        raise ValueError(\"`matmul` does not support scalars.\")\n",
    "\n",
    "    a_is_1d = False\n",
    "    if a.ndim == 1:\n",
    "        a_is_1d = True\n",
    "        a = a[np.newaxis, :]\n",
    "\n",
    "    b_is_1d = False\n",
    "    if b.ndim == 1:\n",
    "        b_is_1d = True\n",
    "        b = b[:, np.newaxis]\n",
    "\n",
    "    if a.ndim < b.ndim:\n",
    "        a = a[(b.ndim - a.ndim) * (np.newaxis,)]\n",
    "    elif a.ndim > b.ndim:\n",
    "        b = b[(a.ndim - b.ndim) * (np.newaxis,)]\n",
    "\n",
    "    # out_ind includes all dimensions to prevent contraction\n",
    "    # in the blockwise below\n",
    "    out_ind = tuple(range(a.ndim + 1))\n",
    "    # lhs_ind includes `a`/LHS dimensions\n",
    "    lhs_ind = tuple(range(a.ndim))\n",
    "    # on `b`/RHS everything above 2nd dimension, is the same\n",
    "    # as `a`, -2 dimension is \"contracted\" with the last dimension\n",
    "    # of `a`, last dimension of `b` is `b` specific\n",
    "    rhs_ind = tuple(range(a.ndim - 2)) + (lhs_ind[-1], a.ndim)\n",
    "\n",
    "    out = blockwise(\n",
    "        _matmul,\n",
    "        out_ind,\n",
    "        a,\n",
    "        lhs_ind,\n",
    "        b,\n",
    "        rhs_ind,\n",
    "        adjust_chunks={lhs_ind[-1]: 1},\n",
    "        dtype=result_type(a, b),\n",
    "        concatenate=False,\n",
    "    )\n",
    "\n",
    "    # Because contraction + concatenate in blockwise leads to high\n",
    "    # memory footprints, we want to avoid them. Instead we will perform\n",
    "    # blockwise (without contraction) followed by reduction. More about\n",
    "    # this issue: https://github.com/dask/dask/issues/6874\n",
    "\n",
    "    # When we perform reduction, we need to worry about the last 2 dimensions\n",
    "    # which hold the matrices, some care is required to handle chunking in\n",
    "    # that space.\n",
    "    contraction_dimension_is_chunked = (\n",
    "        max(min(a.chunks[-1], b.chunks[-2])) < a.shape[-1]\n",
    "    )\n",
    "    b_last_dim_max_chunk = max(b.chunks[-1])\n",
    "    if contraction_dimension_is_chunked or b_last_dim_max_chunk < b.shape[-1]:\n",
    "        if b_last_dim_max_chunk > 1:\n",
    "            # This is the case when both contraction and last dimension axes\n",
    "            # are chunked\n",
    "            out = out.reshape(out.shape[:-1] + (1, -1))\n",
    "            out = out.sum(axis=-3)\n",
    "            out = out.reshape(out.shape[:-2] + (b.shape[-1],))\n",
    "        else:\n",
    "            # Contraction axis is chunked\n",
    "            out = out.sum(axis=-2)\n",
    "    else:\n",
    "        # Neither contraction nor last dimension axes are chunked, we\n",
    "        # remove the dummy dimension without reduction\n",
    "        out = out.reshape(out.shape[:-2] + (b.shape[-1],))\n",
    "\n",
    "    if a_is_1d:\n",
    "        out = out[..., 0, :]\n",
    "    if b_is_1d:\n",
    "        out = out[..., 0]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-villa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
